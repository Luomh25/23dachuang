# 0524

### 1. OCT 图像分类

###a.数据集描述：

包括训练集和测试集，均有4类图像分别是CNV（脉络膜新生血管）、DME（糖尿病性黄斑水肿）、DRUSEN（早期AMD）和NORMAL，训练集共有84495张图片，测试集共有1000张图片。

https://data.mendeley.com/datasets/rscbjbr9sj/2

![cdf33b5f38484bb0b422e45374dfca78](C:\Users\Lucille\Desktop\cdf33b5f38484bb0b422e45374dfca78.png)

b. OCT图像预处理

因为OCT图像具有比较多的噪声，所以在分析之前要进行去噪，裁剪，保留前景区域

具体步骤：读取图像->高斯滤波->图像二值化->中值滤波，轮廓填充->形态学开闭操作->数据拟合->对齐，归一化

​	**高斯滤波**：高斯滤波的优点可以集中在高斯函数的特点上来看。首先，二维高斯函数是旋转对称的，在各个方向上平滑程度相同，不会改变原图像的边缘走向。第二，高斯函数是单值函数，高斯卷积核的锚点为极值，在所有方向上单调递减，锚点像素不会受到距离锚点较远的像素影响过大，保证了特征点和边缘的特性。第三，在频域上，滤波过程中不会被高频信号污染。

​	**图像二值化**：使用阈值过滤填充后的图像，使用平均值作为阈值，对图像进行二值化处理，得到二值图像。找到粗略的前景区域。

​	**中值滤波** ：使用中值滤波的方法对二值图像进行处理，可以去除视网膜内脱落的黑点。轮廓填充是找到二值化图像中的所有区域轮廓，随后对每个轮廓的面积进行统计，然后对具有最大面积的区域进行白色填充作为感兴趣区域。

​	**形态学开闭操作**：图像依次经过腐蚀、膨胀处理后的过程。图像被腐蚀后，去除了噪声，但是也压缩了图像；接着对腐蚀过的图像进行膨胀处理，可以去除噪声，并保留原有图像，通过形态学开运算的方法，设置合适大小的卷积核，去除视网膜外脱落的白点。然后对图像进行闭操作，扩张图片.

### b. 特征提取

用OCT数据集的训练集对ResNet50进行微调10个Epoch，并在ResNet50中插入PDBL模块。使用交叉熵损失函数和SGD优化器训练网络主干，学习率为1e-3，权值衰减率为1e-4，动量为0.9，批次大小为20，所有的图像都将resize至224×224再输入网络
PDBL: Improving Histopathological Tissue Classification with Plug-and-Play Pyramidal Deep-Broad Learning

PDBL模块的代码地址：https://github.com/linjiatai/PDBL

### c. 代码实现





### 2. CNN调参

上次在MNIST数据集上训练的CNN模型达到了99%的正确率，尝试用Fashion_MNIST数据集训练CNN。

```python
from keras.datasets import fashion_mnist

# 加载数据集
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

# 将图像数据转换为浮点数并归一化
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# 定义CNN模型
model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dense(10, activation='softmax'))

# 编译模型
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# 显示模型信息
model.summary()

# 训练模型
model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_test, y_test))

# 评估模型
test_loss, test_acc = model.evaluate(x_test, y_test)
print('Test accuracy:', test_acc)
```

构建了一个包含3个卷积层和2个全连接层的CNN模型。其中，第一层是卷积层，输入的图像大小为28x28x1，输出通道数为32，卷积核大小为3x3，激活函数为ReLU。后面的两个卷积层和池化层的结构类似。最后的两个全连接层分别输出64和10个类别的概率分布，激活函数分别为ReLU和Softmax

使用Adam优化器和稀疏分类交叉熵损失函数来编译模型，并使用训练集进行10个epoch的训练。同时使用测试集进行验证.

测试正确率为90.3%



下面增大卷积层中卷积核的大小：

```python
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.preprocessing.image import ImageDataGenerator
from keras.datasets import fashion_mnist
# 加载数据集
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

# 将图像数据转换为浮点数并归一化
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# 将图像数据转换为四维张量
# 将图像数据转换为四维张量
x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))
x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))

# 定义CNN模型
model = Sequential()
model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(28, 28, 1)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (5, 5), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.25))
model.add(Dense(10, activation='softmax'))

# 编译模型
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])



# 训练模型
model.fit(x_train, y_train, batch_size=100, epochs=10, validation_data=(x_test,y_test))

# 评估模型
test_loss, test_acc = model.evaluate(x_test, y_test)
print('Test accuracy:', test_acc)
```

测试正确率为90.8%



然后在此基础上将优化器改成SGD。

```python
# 训练模型
model.fit(x_train, y_train, batch_size=100, epochs=10, validation_data=(x_test,y_test))

# 评估模型
test_loss, test_acc = model.evaluate(x_test, y_test)
print('Test accuracy:', test_acc)
```

83%



说明还是adam更优，尝试用更大的卷积核

```python
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.preprocessing.image import ImageDataGenerator
from keras.datasets import fashion_mnist

# 加载数据集
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

# 将图像数据转换为浮点数并归一化
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# 将图像数据转换为四维张量
x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))
x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))

# 定义CNN模型
model = Sequential()
model.add(Conv2D(32, (7, 7), activation='relu', input_shape=(28, 28, 1)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (5, 5), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.25))
model.add(Dense(10, activation='softmax'))

# 编译模型
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# 训练模型
model.fit(x_train, y_train, batch_size=100, epochs=10, validation_data=(x_test,y_test))

# 评估模型
test_loss, test_acc = model.evaluate(x_test, y_test)
print('Test accuracy:', test_acc)
```

89.5%