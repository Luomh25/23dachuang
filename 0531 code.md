# 0531 code

## Medical Image Denoising using Autoencoders

```python
from google.colab import drive
drive.mount('/content/drive')
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
for dirname, _, filenames in os.walk('/content/drive/MyDrive/0531Dataset'):
    for filename in filenames:
        print(os.path.join(dirname, filename))
```

改变图像大小和数据：

```python
train_images = []
for im in train_image：
    img = image.load_img('/content/drive/MyDrive/0531Dataset/'+ im, target_size=(64,64), color_mode= 'grayscale')
    img = image.img_to_array(img)
    img = img/255
    train_image.append(img)
train_df = np.array(train_image)

import matplotlib.pyplot as plt
#Defining a plot function
def show_img(dataset):
    f, ax = plt.subplots(1,5)
    f.set_size_inches(40, 20)
    for i in range(5,10):
        ax[i-5].imshow(dataset[i].reshape(64,64), cmap='gray')
    plt.show()

#Defining a function for Noice addition. 0.07 is multiplied as it is the fraction of noice that we want in our picture.
def add_noice(image):
    row,col,ch= image.shape
    mean = 0
    sigma = 1
    gauss = np.random.normal(mean,sigma,(row,col,ch))
    gauss = gauss.reshape(row,col,ch)
    noisy = image + gauss*0.07
    return noisy
  
noised_df= []

for img in train_df:
    noisy= add_noice(img)
    noised_df.append(noisy)
noised_df= np.array(noised_df)
show_img(train_df)
show_img(noised_df)

```

![微信图片_20230530230717](C:\Users\Lucille\Desktop\dachuang\biostat\materials\0531\微信图片_20230530230717.png)

Define the model:

```python
from keras.models import Sequential, Model
from keras.layers import Dense, Conv2D, MaxPooling2D,MaxPool2D ,UpSampling2D, Flatten, Input
from keras.optimizers import SGD, Adam, Adadelta, Adagrad
from keras import backend as K

def autoencoder():
    
    input_img = Input(shape=(64,64,1), name='image_input')
    
    #enoder 
    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1')(input_img)
    x = MaxPooling2D((2,2), padding='same', name='pool1')(x)
    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv2')(x)
    x = MaxPooling2D((2,2), padding='same', name='pool2')(x)
    
    #decoder
    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv3')(x)
    x = UpSampling2D((2,2), name='upsample1')(x)
    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv4')(x)
    x = UpSampling2D((2,2), name='upsample2')(x)
    x = Conv2D(1, (3,3), activation='sigmoid', padding='same', name='Conv5')(x)
    
    #model
    autoencoder = Model(inputs=input_img, outputs=x)
    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')
    return autoencoder
```

```python
model= autoencoder()
model.summary()
```

```python
import tensorflow as tf
from tensorflow.keras.callbacks import EarlyStopping
with tf.device('/device:GPU:0'):
    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')
model.fit(xnoised, xnoised, epochs=40, batch_size=10, validation_data=(xtest, xtest),callbacks=[early_stopping])
```

```
Epoch 1/40
10/10 [==============================] - 0s 30ms/step - loss: 0.6708 - val_loss: 0.6524
Epoch 2/40
10/10 [==============================] - 0s 7ms/step - loss: 0.6143 - val_loss: 0.5976
Epoch 3/40
10/10 [==============================] - 0s 7ms/step - loss: 0.5897 - val_loss: 0.5850
Epoch 4/40
10/10 [==============================] - 0s 7ms/step - loss: 0.5786 - val_loss: 0.5777
Epoch 5/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5723 - val_loss: 0.5740
Epoch 6/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5684 - val_loss: 0.5711
Epoch 7/40
10/10 [==============================] - 0s 7ms/step - loss: 0.5660 - val_loss: 0.5696
Epoch 8/40
10/10 [==============================] - 0s 7ms/step - loss: 0.5643 - val_loss: 0.5671
Epoch 9/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5624 - val_loss: 0.5649
Epoch 10/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5615 - val_loss: 0.5641
Epoch 11/40
10/10 [==============================] - 0s 9ms/step - loss: 0.5605 - val_loss: 0.5638
Epoch 12/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5607 - val_loss: 0.5629
Epoch 13/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5598 - val_loss: 0.5623
Epoch 14/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5588 - val_loss: 0.5646
Epoch 15/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5588 - val_loss: 0.5612
Epoch 16/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5579 - val_loss: 0.5618
Epoch 17/40
10/10 [==============================] - 0s 8ms/step - loss: 0.5577 - val_loss: 0.5604
Epoch 18/40
10/10 [==============================] - 0s 11ms/step - loss: 0.5572 - val_loss: 0.5614
Epoch 19/40
10/10 [==============================] - 0s 9ms/step - loss: 0.5571 - val_loss: 0.5603
Epoch 20/40
10/10 [==============================] - 0s 7ms/step - loss: 0.5564 - val_loss: 0.5598
Epoch 21/40
10/10 [==============================] - 0s 7ms/step - loss: 0.5561 - val_loss: 0.5599
Epoch 22/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5560 - val_loss: 0.5611
Epoch 23/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5563 - val_loss: 0.5603
Epoch 24/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5555 - val_loss: 0.5592
Epoch 25/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5551 - val_loss: 0.5588
Epoch 26/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5548 - val_loss: 0.5590
Epoch 27/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5554 - val_loss: 0.5586
Epoch 28/40
10/10 [==============================] - 0s 7ms/step - loss: 0.5548 - val_loss: 0.5585
Epoch 29/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5543 - val_loss: 0.5584
Epoch 30/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5541 - val_loss: 0.5584
Epoch 31/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5542 - val_loss: 0.5581
Epoch 32/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5548 - val_loss: 0.5598
Epoch 33/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5542 - val_loss: 0.5583
Epoch 34/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5536 - val_loss: 0.5579
Epoch 35/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5536 - val_loss: 0.5577
Epoch 36/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5535 - val_loss: 0.5579
Epoch 37/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5531 - val_loss: 0.5577
Epoch 38/40
10/10 [==============================] - 0s 7ms/step - loss: 0.5529 - val_loss: 0.5576
Epoch 39/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5530 - val_loss: 0.5589
Epoch 40/40
10/10 [==============================] - 0s 6ms/step - loss: 0.5530 - val_loss: 0.5587
```

```python
xtrain= train_df[100:]
## plot the prediction
import cv2

pred= model.predict(xtest[:5])
def plot_predictions(y_true, y_pred):    
    f, ax = plt.subplots(4, 5)
    f.set_size_inches(10.5,7.5)
    for i in range(5):
        ax[0][i].imshow(np.reshape(xtrain[i], (64,64)), aspect='auto', cmap='gray')
        ax[1][i].imshow(np.reshape(y_true[i], (64,64)), aspect='auto', cmap='gray')
        ax[2][i].imshow(np.reshape(y_pred[i], (64,64)), aspect='auto', cmap='gray')
        ax[3][i].imshow(cv2.medianBlur(xtrain[i], (5)), aspect='auto', cmap='gray') #中值滤波结果
       
    plt.tight_layout()
plot_predictions(xtest[:5], pred[:5])
```

第一行：原始数据

第二行：噪声数据

第三行：用Autoencoder去噪之后的图像

第四行：中值滤波图像

![微信图片_20230530231323](C:\Users\Lucille\Desktop\dachuang\biostat\materials\0531\微信图片_20230530231323.png)

```python
new_image = cv2.medianBlur(xtrain[0], (5))
plt.figure(figsize=(6,3))
plt.subplot(121)
plt.imshow(pred[0].reshape(64,64), cmap='gray')
plt.title('Autoencoder Image')
plt.xticks([])
plt.yticks([])
plt.subplot(122)
plt.imshow(new_image, cmap='gray')
plt.title('Median Filter')
plt.xticks([])
plt.yticks([])
plt.show()
```

![微信图片_20230530231415](C:\Users\Lucille\Desktop\dachuang\biostat\materials\0531\微信图片_20230530231415.png)

```python
from math import log10, sqrt 
  
def PSNR(original, denoiced): 
    mse = np.mean((original - denoiced) ** 2) 
    if(mse == 0):  # MSE is zero means no noise is present in the signal . 
                  # Therefore PSNR have no importance. 
        return 100
    max_pixel = 255.0
    psnr = 20 * log10(max_pixel / sqrt(mse)) 
    return psnr 
  
value1 = PSNR(xtest[0], new_image)
value2 = PSNR(xtest[0], pred[0])

print(f"PSNR value for Denoised image is {value2} dB while for Median filtered image is {value1} dB")
```

PSNR value for Denoised image is 69.8926313092242 dB while for Median filtered image is 58.45508992511279 dB

【换个指标



### 服务器下的一些尝试

由于时间较紧所以做得比较少

```python
import matplotlib.pyplot as plt # 导入matplotlib库
import pandas as pd
##测试一下路径是否正确，是否能够读取信息
train_dir = "/public/home/tianting/UKB/data/image/21015"

datanames = os.listdir(train_dir)
names = []
for dataname in datanames:
    if os.path.splitext(dataname)[1] == '.png':#目录下包含.json的文件
        names.append(dataname)
        print(dataname)

test = pd.DataFrame(data = names)

print(test)

test.to_csv('/public/home/tianting/23dachuang/LYN/0531.csv')
##图像的一些处理的尝试
import os
import cv2

# 遍历文件夹中的所有文件
for file_name in os.listdir(train_dir):
    # 判断文件是否为图片文件（可根据需求修改文件类型）
    if file_name.endswith('.jpg') or file_name.endswith('.jpeg') or file_name.endswith('.png'):
        # 读取图片文件
        img = cv2.imread(os.path.join(train_dir, file_name))
        # 在此处对图片进行处理
        img = image.img_to_array(img)
    img = img/255
    train_image.append(img)
train_df = np.array(train_image)
print("ok")


# 关闭窗口
cv2.destroyAllWindows()
```

Traceback (most recent call last):
  File "/public/home/tianting/23dachuang/LYN/0531/run_image.py", line 6, in <module>

```
datanames = os.listdir(train_dir)
```

NameError: name 'os' is not defined

